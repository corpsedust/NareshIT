# -*- coding: utf-8 -*-
"""
Created on Wed Mar 26 19:32:58 2025

@author: vineet

"""


#Multilinear Regression 
#Adde a row of 1 to add constant, I do not know why


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#Import data 

df = pd.read_csv("Investment.csv")

#split into dependent variable and independent variable
x = df.iloc[:, :-2]
y = df.iloc[:,4]

#Convert categorical data to numerical
#eliminates the categorical column with numerical columns for each
#category in city

#Dummies = Transformers = Imputation

x = pd.get_dummies(x, dtype = int)



#Splitting data into training and testing model

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, train_size = 0.8, random_state=0)


from sklearn.linear_model import LinearRegression
model = LinearRegression()

model.fit(x_train, y_train)
y_pred = model.predict(x_test)
comparison = pd.DataFrame({"Actual":y_test, "Predicted":y_pred})


#y_pred is same as y_test


#slope
m_slope = model.coef_
print(m_slope)


#intercept

c_inter = model.intercept_
print(c_inter)


#WHAT HAPPENED HERE??
X = np.append(arr = np.ones((50,1)).astype(int), values = x, axis = 1)


import statsmodels.api as sm
X_opt =  X[:,[0,1,2,3,4,5]]


#OrdinaryLeastSquares

regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()
regressor_OLS.summary()


#Backward Elimination - If p-value(0.05) value is > significant value generated by model(Remove that variable, feature)
#Forward Elimination - 
#Recurssive Elimination
#Feature Elimination

#Remove x




















